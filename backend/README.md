# Agromate Backend

Backend en Python para scraping y anÃ¡lisis de noticias agropecuarias argentinas.

## ğŸ“‹ Fases Completadas: Fase 1, 2 y 3

### âœ… Archivos Creados

```
backend/
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ news.py             # Modelo News (dataclass)
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py      # Clase base abstracta
â”‚   â”œâ”€â”€ rss_scraper.py       # ImplementaciÃ³n RSS
â”‚   â””â”€â”€ sources.py          # Fuentes RSS configuradas
â”œâ”€â”€ sentiment/              # âœ¨ NUEVO en Fase 3
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py        # MockLLMClient
â”‚   â”œâ”€â”€ analyzer.py          # SentimentAnalyzer
â”‚   â””â”€â”€ README.md           # DocumentaciÃ³n del mÃ³dulo
â”œâ”€â”€ test_scraper.py          # Script de prueba scraping
â”œâ”€â”€ test_sentiment.py        # âœ¨ NUEVO: Script de prueba sentiment
â””â”€â”€ .env.example            # Template de variables de entorno
```

## ğŸš€ InstalaciÃ³n

### 1. Crear entorno virtual

```powershell
python -m venv venv
```

### 2. Activar entorno virtual

```powershell
.\venv\Scripts\Activate
```

### 3. Instalar dependencias

```powershell
pip install -r requirements.txt
```

## ğŸ“° Fuentes RSS Configuradas

| Fuente | URL | Status |
|--------|-----|--------|
| ğŸŒ¾ Bichos de Campo | `https://bichosdecampo.com/feed/` | âœ… Activa |
| ğŸ“° Agrofynews | `https://news.agrofy.com.ar/rss.xml` | âœ… Activa |
| ğŸŒ± Infocampo | `https://www.infocampo.com.ar/feed/` | âœ… Activa |

## ğŸ§ª Testing

### Ejecutar test del scraper

```powershell
.\venv\Scripts\python test_scraper.py
```

**Salida esperada:**
```
================================================================================
ğŸŒ¾ AGROMATE - RSS Scraper Test
================================================================================

ğŸ“° Testing: Bichos de Campo
   URL: https://bichosdecampo.com/feed/
--------------------------------------------------------------------------------
âœ… Success! Found 16 articles

   [1] TÃ­tulo de la noticia...
       ğŸ“… 2026-01-31 14:35:08
       ğŸ”— https://...

ğŸ¯ Total articles scraped: 26
================================================================================
```

### Ejecutar test de anÃ¡lisis de sentimiento

```powershell
.\venv\Scripts\python test_sentiment.py
```

**Salida esperada:**
```
================================================================================
ğŸŒ¾ AGROMATE - Sentiment Analysis Test
================================================================================

ğŸ“° Step 1: Scraping news from Bichos de Campo...
âœ… Scraped 5 articles for testing

ğŸ¤– Step 2: Analyzing sentiment (using Mock LLM)...

ğŸ“Š Step 3: Sentiment Analysis Results
================================================================================

[1] DÃ³lar Blue en CÃ³rdoba: precio y cotizaciÃ³n...
    ğŸŸ¢ ALCISTA (confidence: 0.87)
    ğŸ“… 2026-01-31 14:35:08
    ğŸ”— https://bichosdecampo.com/...

ğŸ“ˆ Sentiment Summary
Total analyzed: 5 articles

ğŸŸ¢ ALCISTA:   2 ( 40.0%)
ğŸ”´ BAJISTA:   1 ( 20.0%)
âšª NEUTRAL:   2 ( 40.0%)
================================================================================
```

## ğŸ’» Uso ProgramÃ¡tico

```python
import asyncio
from scrapers import RSScraper, get_active_sources

async def main():
    # Scraping una fuente especÃ­fica
    scraper = RSScraper(source_name="Bichos de Campo")
    news_items = await scraper.scrape("https://bichosdecampo.com/feed/")
    
    for article in news_items:
        print(f"{article.title}")
        print(f"  Fuente: {article.source}")
        print(f"  URL: {article.url}")
        print(f"  Fecha: {article.published_at}")

asyncio.run(main())
```

## ğŸ“¦ Modelo de Datos

### News Dataclass

```python
@dataclass
class News:
    title: str                           # TÃ­tulo de la noticia
    source: str                          # Nombre de la fuente
    url: str                             # URL del artÃ­culo
    published_at: Optional[datetime]     # Fecha de publicaciÃ³n
```

## ğŸ”§ ConfiguraciÃ³n

### Agregar nueva fuente RSS

Editar `scrapers/sources.py`:

```python
RSS_SOURCES.append({
    "name": "Nueva Fuente",
    "url": "https://nuevafuente.com/feed/",
    "enabled": True,
})
```

### Deshabilitar una fuente

Cambiar `enabled` a `False` en `scrapers/sources.py`.

## ğŸ§© Arquitectura

### BaseScraper (Clase Abstracta)

Define la interfaz que todos los scrapers deben implementar:
- MÃ©todo abstracto: `async def scrape(self, url: str) -> List[News]`
- Logging automÃ¡tico

### RSScraper (ImplementaciÃ³n)

CaracterÃ­sticas:
- âœ… Parseo de feeds RSS/Atom
- âœ… NormalizaciÃ³n de fechas mÃºltiples formatos
- âœ… Manejo robusto de errores
- âœ… ValidaciÃ³n de entradas
- âœ… Logging detallado

## ğŸ“š Dependencias Instaladas

- **fastapi** (0.115.0) - Framework web (para futura API)
- **uvicorn** (0.32.0) - Servidor ASGI
- **feedparser** (6.0.11) - Parser de feeds RSS
- **pydantic** (1.10.18) - ValidaciÃ³n de datos
- **python-dotenv** (1.0.1) - Variables de entorno
- **httpx** (0.27.2) - Cliente HTTP async

## âœ¨ CaracterÃ­sticas Implementadas

### Fase 1 y 2: Scraping
- âœ… Scraping asÃ­ncrono de mÃºltiples fuentes RSS
- âœ… Modelo de datos validado (News dataclass)
- âœ… Manejo de errores robusto
- âœ… NormalizaciÃ³n de fechas en mÃºltiples formatos
- âœ… Logging estructurado
- âœ… Arquitectura extensible con clase base abstracta
- âœ… Test script funcional

### Fase 3: AnÃ¡lisis de Sentimiento
- âœ… MockLLMClient con sentimientos aleatorios
- âœ… SentimentAnalyzer para procesar noticias
- âœ… ClasificaciÃ³n: ALCISTA / BAJISTA / NEUTRAL
- âœ… Scores de confianza (0.70 - 0.99)
- âœ… AnÃ¡lisis individual y batch
- âœ… EstadÃ­sticas agregadas de sentimiento
- âœ… Test script integrado (scraping + anÃ¡lisis)
- âœ… Preparado para migrar a LLM real (OpenAI/Claude)

## ğŸ”œ PrÃ³ximos Pasos (Fase 4)

La siguiente fase incluirÃ¡:

1. **IntegraciÃ³n con Supabase** (`database/`)
   - `supabase_client.py` - Cliente de conexiÃ³n
   - `repositories.py` - CRUD operations
   - MigraciÃ³n SQL para tabla `news`

2. **Persistencia de Datos**
   - Guardar noticias scrapeadas
   - Almacenar anÃ¡lisis de sentimiento
   - Evitar duplicados por URL

---

**Status:** âœ… Fase 1, 2 y 3 completadas  
**Tests:** âœ… 26 artÃ­culos scrapeados + 5 analizados exitosamente  
**Siguiente:** IntegraciÃ³n con Supabase (Base de Datos)
